{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "751b88d5",
      "metadata": {},
      "source": [
        "### üì¶ Installing Required Packages\n",
        "\n",
        "To ensure all dependencies for the project are installed, we use the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a91763d",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0575c78a",
      "metadata": {
        "id": "0575c78a"
      },
      "source": [
        "### üõ†Ô∏è Import Required Modules and Classes\n",
        "\n",
        "This block loads all essential modules and classes from the `sokegraph` package and its dependencies. These components enable the full pipeline, including:\n",
        "\n",
        "- **Paper sources**  \n",
        "  Retrieve papers from:\n",
        "  - **Semantic Scholar**\n",
        "  - **PDF ZIP files**\n",
        "  - **Journal API**\n",
        "\n",
        "- **Paper ranking engine**  \n",
        "  Score and prioritize papers based on:\n",
        "  - Keyword relevance  \n",
        "  - Synonym and concept expansion  \n",
        "  - Opposite keyword filtering  \n",
        "\n",
        "- **Knowledge graph interface**  \n",
        "  Build and manage graphs using:\n",
        "  - **Neo4j**\n",
        "  - **NetworkX**\n",
        "\n",
        "- **AI agents**  \n",
        "  Integrate powerful language models:\n",
        "  - **OpenAI**\n",
        "  - **Gemini**\n",
        "  - **LLaMA**\n",
        "  - **Ollama**\n",
        "  - **Claude**\n",
        "\n",
        "- **Ontology management**  \n",
        "  Update and expand ontologies based on enriched content and paper metadata.\n",
        "\n",
        "- **Logging & configuration**  \n",
        "  Monitor pipeline progress and capture errors or debug messages via the custom logging system.\n",
        "\n",
        "- **JSON and file handling**  \n",
        "  Load configurations, queries, ontologies, and export results efficiently.\n",
        "\n",
        "These imports prepare the environment for the full research pipeline: from **paper collection**, **ontology enrichment**, **paper ranking**, and **graph construction**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d48c387b",
      "metadata": {
        "id": "d48c387b"
      },
      "outputs": [],
      "source": [
        "from sokegraph.base_paper_source import BasePaperSource\n",
        "from sokegraph.semantic_scholar_source import SemanticScholarPaperSource\n",
        "from sokegraph.pdf_paper_source import PDFPaperSource\n",
        "from sokegraph.paper_ranker import PaperRanker\n",
        "from sokegraph.knowledge_graph import KnowledgeGraph\n",
        "from sokegraph.util.logger import LOG\n",
        "from sokegraph.ai_agent import AIAgent\n",
        "from sokegraph.openai_agent import OpenAIAgent\n",
        "from sokegraph.gemini_agent import GeminiAgent\n",
        "from sokegraph.ontology_updater import OntologyUpdater\n",
        "from sokegraph.neo4j_knowledge_graph import Neo4jKnowledgeGraph\n",
        "from sokegraph.llama_agent import LlamaAgent\n",
        "from sokegraph.ollama_agent import OllamaAgent\n",
        "from sokegraph.claude_agent import ClaudeAgent\n",
        "from sokegraph.journal_api_source import JournalApiPaperSource\n",
        "from sokegraph.networkx_knowledge_graph import NetworkXKnowledgeGraph\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88f6c68a",
      "metadata": {
        "id": "88f6c68a"
      },
      "source": [
        "# Initialize and Display the User Interface\n",
        "\n",
        "- The `SOKEGraphUI` class is imported from the `ui_inputs` module.\n",
        "- An instance of `SOKEGraphUI` is created and assigned to `ui`.\n",
        "- The `display_ui()` method is called to render the interactive user interface.\n",
        "\n",
        "> **Note:**  \n",
        "> If you make changes to `ui_inputs.py`, you might need to uncomment the `importlib.reload` lines to reload the module without restarting the notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c16b2d7",
      "metadata": {
        "id": "9c16b2d7"
      },
      "outputs": [],
      "source": [
        "import importlib\n",
        "import sokegraph.ui_inputs\n",
        "importlib.reload(sokegraph.ui_inputs)\n",
        "from sokegraph.ui_inputs import SOKEGraphUI\n",
        "\n",
        "print(\"shahlla\")\n",
        "\n",
        "# Create UI instance\n",
        "ui = SOKEGraphUI()\n",
        "\n",
        "# Display the UI in the notebook\n",
        "ui.display_ui()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d08e6b9",
      "metadata": {
        "id": "9d08e6b9"
      },
      "source": [
        "## üß† Step 0: Setup AI Agent\n",
        "\n",
        "- Begins the pipeline by logging its initialization.\n",
        "- Selects and initializes the appropriate AI agent based on the `AI` parameter from the user interface.\n",
        "- Supports the following AI providers:\n",
        "  - `openAI` ‚Üí initializes an `OpenAIAgent` with the specified API keys file.\n",
        "  - `gemini` ‚Üí initializes a `GeminiAgent`.\n",
        "  - `llama` ‚Üí initializes a `LlamaAgent`.\n",
        "  - `ollama` ‚Üí initializes an `OllamaAgent`.\n",
        "  - `claude` ‚Üí initializes a `ClaudeAgent`.\n",
        "- Raises an error if an unsupported provider is selected.\n",
        "\n",
        "> ‚ö†Ô∏è **Important:**  \n",
        "> Ensure the API keys file specified in `ui.params.api_keys_file` exists and contains valid credentials for the selected AI provider.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d563fa7c",
      "metadata": {
        "id": "d563fa7c"
      },
      "outputs": [],
      "source": [
        "LOG.info(\"üöÄ Starting Full Pipeline\")\n",
        "\n",
        "# 0. Setup AI agent\n",
        "ai_tool: AIAgent\n",
        "if ui.params.AI == \"openAI\":\n",
        "    ai_tool = OpenAIAgent(ui.params.api_keys_file)\n",
        "elif ui.params.AI == \"gemini\":\n",
        "    ai_tool = GeminiAgent(ui.params.api_keys_file)\n",
        "elif ui.params.AI == \"llama\":\n",
        "    ai_tool = LlamaAgent(ui.params.api_keys_file)\n",
        "elif ui.params.AI == \"ollama\":\n",
        "    ai_tool = OllamaAgent()\n",
        "elif ui.params.AI == \"claude\":\n",
        "    ai_tool = ClaudeAgent(ui.params.journal_api_key_file)\n",
        "else:\n",
        "    raise ValueError(f\"Unsupported AI provider: {ui.params.AI}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "413384bf",
      "metadata": {
        "id": "413384bf"
      },
      "source": [
        "## üìÑ Step 1: Select Paper Source\n",
        "\n",
        "- Determines the paper source based on user input:\n",
        "  - If `number_papers` and a `paper_query_file` are provided, papers are retrieved from **Semantic Scholar** using the `SemanticScholarPaperSource` class.\n",
        "  - If a ZIP file of PDFs (`pdfs_file`) is provided (and `number_papers` is not), papers are extracted using the `PDFPaperSource` class.\n",
        "  - If the paper source is set to **Journal API**, it uses the `JournalApiPaperSource` class with the query file and API key.\n",
        "\n",
        "- Logs an error if:\n",
        "  - The query file is missing when using Semantic Scholar or Journal API.\n",
        "  - Both `number_papers` and `pdfs_file` are provided (conflict).\n",
        "  - Neither option is specified.\n",
        "\n",
        "- Calls `fetch_papers()` on the selected paper source class to retrieve papers.\n",
        "\n",
        "> ‚ö†Ô∏è **Important:**  \n",
        "> - You must specify **either**:\n",
        ">   - `number_papers` + `paper_query_file`, **or**\n",
        ">   - a `pdfs_file`, **or**\n",
        ">   - `number_papers` + `paper_query_file` + `journal_api_key_file`.\n",
        "> - The `fetch_papers()` method returns a list of paper metadata dictionaries that will be used in later steps.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49f761ca",
      "metadata": {
        "id": "49f761ca"
      },
      "outputs": [],
      "source": [
        "# 1. Select paper source\n",
        "paper_source: BasePaperSource\n",
        "\n",
        "if ui.params.paper_source == \"Semantic Scholar\":\n",
        "    if not ui.params.number_papers or not ui.params.paper_query_file:\n",
        "        LOG.error(\"‚ùå 'number_papers' and 'paper_query_file' are required for Semantic Scholar source.\")\n",
        "    else:\n",
        "        paper_source = SemanticScholarPaperSource(\n",
        "            num_papers=int(ui.params.number_papers),\n",
        "            query_file=ui.params.paper_query_file,\n",
        "            output_dir=ui.params.output_dir\n",
        "        )\n",
        "\n",
        "elif ui.params.paper_source == \"PDF Zip\":\n",
        "    if not ui.params.pdfs_file:\n",
        "        LOG.error(\"‚ùå 'pdfs_file' (ZIP file) is required for PDF source.\")\n",
        "    else:\n",
        "        paper_source = PDFPaperSource(\n",
        "            zip_path=ui.params.pdfs_file,\n",
        "            output_dir=ui.params.output_dir\n",
        "        )\n",
        "\n",
        "elif ui.params.paper_source == \"Journal API\":\n",
        "    if not ui.params.paper_query_file or not ui.params.api_key_file:\n",
        "        LOG.error(\"‚ùå 'paper_query_file' and 'api_key_file' are required for Journal API source.\")\n",
        "    else:\n",
        "        paper_source = JournalApiPaperSource(\n",
        "            query_file=ui.params.paper_query_file,\n",
        "            api_key_file=ui.params.api_key_file,\n",
        "            output_dir=ui.params.output_dir\n",
        "        )\n",
        "\n",
        "else:\n",
        "    LOG.error(\"‚ùå Invalid or unsupported paper source selected.\")\n",
        "    paper_source = None\n",
        "\n",
        "# 2. Fetch papers\n",
        "if paper_source:\n",
        "    papers = paper_source.fetch_papers()\n",
        "else:\n",
        "    papers = []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ea17bb4",
      "metadata": {
        "id": "2ea17bb4"
      },
      "source": [
        "## üß† Step 2: Update Ontology Using Retrieved Papers\n",
        "\n",
        "- Creates an instance of `OntologyUpdater` to enrich the ontology file using:\n",
        "  - The retrieved papers,\n",
        "  - The selected AI tool (`ai_tool`),\n",
        "  - The specified output directory for saving results.\n",
        "\n",
        "- The ontology file (`ontology_file`) contains a structured hierarchy of domain-specific concepts (e.g., in materials science).\n",
        "\n",
        "- Calls `enrich_with_papers()` to:\n",
        "  - Extract relevant concepts and keywords from the papers,\n",
        "  - Integrate these insights into the ontology.\n",
        "\n",
        "> üîç **What this step does:**\n",
        "> - Associates papers with ontology categories by analyzing their content using the selected LLM agent.\n",
        "> - Produces structured `updated_ontology` used for downstream tasks like paper ranking and graph construction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6070a6a9",
      "metadata": {
        "id": "6070a6a9"
      },
      "outputs": [],
      "source": [
        "# 2. Update ontology\n",
        "ontology_updater = OntologyUpdater(ui.params.ontology_file, papers, ai_tool, ui.params.output_dir)  # or however you instantiate it\n",
        "updated_ontology_path = ontology_updater.enrich_with_papers()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "889b03d6",
      "metadata": {
        "id": "889b03d6"
      },
      "source": [
        "## üìä Step 3: Rank Papers Based on Ontology and Keywords\n",
        "\n",
        "- Instantiate the `PaperRanker` using:\n",
        "  - The selected AI tool (`ai_tool`)\n",
        "  - The list of fetched papers\n",
        "  - The enriched ontology output path (`ontology_updater.output_path`)\n",
        "  - The keyword file (`keywords_file`) containing domain-specific or user-defined terms\n",
        "  - The output directory for saving ranking results\n",
        "\n",
        "- Call `rank_papers()` to:\n",
        "  - Match each paper to ontology categories using keyword relevance\n",
        "  - Score and rank papers based on alignment with user interests\n",
        "  - Optionally filter out papers that focus on **opposite concepts** (e.g., exclude ‚Äúinsulator‚Äù if your focus is ‚Äúconductor‚Äù)\n",
        "\n",
        "> üß† **What this step does:**\n",
        "> - Produces a ranked list of relevant papers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdd6e5eb",
      "metadata": {
        "id": "cdd6e5eb"
      },
      "outputs": [],
      "source": [
        "# 3. Rank papers\n",
        "#LOG.info(\"ranking papers ....\")\n",
        "ranker = PaperRanker(ai_tool, papers, ontology_updater.output_path, ui.params.keywords_file, ui.params.output_dir)\n",
        "rank_paper_output = ranker.rank_papers()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce951e6e",
      "metadata": {
        "id": "ce951e6e"
      },
      "source": [
        "## üï∏ Step 4: Build the Knowledge Graph\n",
        "\n",
        "This step constructs a **knowledge graph** from the enriched ontology, enabling structured querying, visualization, and semantic exploration of materials-related knowledge.\n",
        "\n",
        "### üîß What happens here:\n",
        "- Loads credentials for the selected graph backend (if required) from a JSON file.\n",
        "- Depending on the chosen knowledge graph type (`kg_type`):\n",
        "  - For **Neo4j**:\n",
        "    - Initializes a `Neo4jKnowledgeGraph` instance with the enriched ontology file and connection details (URI, username, password).\n",
        "    - Calls `.build_graph()` to create the graph inside the Neo4j database.\n",
        "  - For **NetworkX**:\n",
        "    - Initializes a `NetworkXKnowledgeGraph` instance (or similar) with the enriched ontology file.\n",
        "    - Builds an in-memory graph representation using NetworkX.\n",
        "- Both approaches generate structured nodes and relationships representing ontology concepts, papers, and their links.\n",
        "\n",
        "> ‚úÖ **Result:**  \n",
        "> A knowledge graph (either in Neo4j or as a NetworkX object) representing categorized concepts and their relationships‚Äîready for exploration, visualization, or further analysis.\n",
        "\n",
        "---\n",
        "\n",
        "üéâ **Pipeline Complete!**  \n",
        "You've successfully:  \n",
        "1. Retrieved papers  \n",
        "2. Enriched the ontology  \n",
        "3. Ranked relevant publications  \n",
        "4. Built a knowledge graph with your selected backend  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "066db0ae",
      "metadata": {
        "id": "066db0ae"
      },
      "outputs": [],
      "source": [
        "# 4. Build knowledge graph\n",
        "LOG.info(\" Building knowledge graph ....\")\n",
        "\n",
        "\n",
        "#### build graph\n",
        "graph_builder: KnowledgeGraph\n",
        "if(ui.params.kg_type == \"neo4j\"):\n",
        "    ### load\n",
        "    with open(ui.params.kg_credentials_file, \"r\") as f:\n",
        "        credentials = json.load(f)\n",
        "    graph_builder = Neo4jKnowledgeGraph(ontology_updater.output_path,\n",
        "                                        credentials[\"neo4j_uri\"],\n",
        "                                        credentials[\"neo4j_user\"],\n",
        "                                        credentials[\"neo4j_pass\"])\n",
        "elif(ui.params.kg_type == \"networkx\"):\n",
        "    graph_builder = NetworkXKnowledgeGraph(ontology_updater.output_path)\n",
        "\n",
        "graph_builder.build_graph()\n",
        "\n",
        "\n",
        "LOG.info(\"üéâ Pipeline Completed Successfully\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "sokegraph",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
