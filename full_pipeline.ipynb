{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6e5c0898",
      "metadata": {},
      "outputs": [],
      "source": [
        "from types import SimpleNamespace\n",
        "params = SimpleNamespace(\n",
        "    paper_source=\"semantic scholar\",\n",
        "    number_papers=10,  # Number of papers to fetch from Semantic Scholar (if not using PDFs)\n",
        "    paper_query_file=\"topics.txt\",  # Text file with one search query per line\n",
        "    pdfs_file=None,  # Optional: ZIP file with PDFs, if using PDF input instead of Semantic Scholar\n",
        "    api_key_journal_api = \"api_journal_api.txt\",\n",
        "    ontology_file=\"base_ontology.json\",  # Base ontology file in JSON or OWL format\n",
        "    AI=\"openAI\",  # Choose the AI model: \"openAI\", \"gemini\", \"llama\", \"ollama\", or \"claude\"\n",
        "    API_keys=\"openai_keys.json\",  # Path to your API keys file (required for OpenAI/Gemini/LLaMA)\n",
        "    keyword_query_file=\"keywords.txt\",  # Text file listing keywords to extract and rank by\n",
        "    model_knowledge_graph=\"neo4j\",  # Graph backend: \"neo4j\" or \"networkx\"\n",
        "    credentials_for_knowledge_graph=\"neo4j_credentials.json\",  # JSON file with graph DB credentials (e.g., URI, user, password)\n",
        "    output_dir=\"output/\",  # Directory where results and metadata will be saved\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4861e3e0",
      "metadata": {},
      "source": [
        "### ðŸš€ Run the Full SOKEGraph Pipeline\n",
        "\n",
        "After youâ€™ve defined your **`params`** dictionary in a code cell, run the entire pipeline with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5961e46",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sokegraph.full_pipeline import full_pipeline_main\n",
        "\n",
        "full_pipeline_main(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1ebc0b4",
      "metadata": {},
      "source": [
        "### âœ… What Happens Under the Hood\n",
        "\n",
        "#### ðŸ“„ Paper Retrieval\n",
        "Fetches papers from **Semantic Scholar** or loads PDFs from your ZIP file.\n",
        "\n",
        "#### ðŸ§  Ontology Enrichment\n",
        "Uses the chosen AI agent (`openAI`, `gemini`, or `llama`) to add new concepts and metadata to your ontology file.\n",
        "\n",
        "#### ðŸ“Š Paper Ranking\n",
        "Ranks and scores papers based on:\n",
        "- Keyword relevance  \n",
        "- Synonyms and expanded concepts  \n",
        "- Opposite keyword filtering\n",
        "\n",
        "#### ðŸ•¸ Knowledge Graph Construction\n",
        "Builds a **Neo4j** knowledge graph (`model_knowledge_graph = \"neo4j\"`) with:\n",
        "- Layers and categories from ontology  \n",
        "- Paper-to-concept relationships  \n",
        "- Metadata and paper links\n",
        "\n",
        "#### ðŸ’¾ Output Saving\n",
        "Stores results inside your specified `output_dir`, including:\n",
        "- Updated ontology  \n",
        "- Ranked papers  \n",
        "- Logs and summaries\n",
        "\n",
        "> ðŸ’¡ **Tip:** Make sure your `params` paths are correct and that all required services (like **Neo4j** or **Ollama**) are up and running before execution.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "sokegraph",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
